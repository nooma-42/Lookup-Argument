#!/bin/bash

# Benchmark with Incremental CSV Writing and Failure Tracking
# This script demonstrates the new features added to the benchmark system

echo "ğŸš€ Lookup Argument Benchmark with Incremental CSV Writing"
echo "========================================================"

# Clean up previous results
if [ -f "benchmark_results.csv" ]; then
    echo "ğŸ—‘ï¸  Removing previous benchmark_results.csv"
    rm benchmark_results.csv
fi

if [ -f "benchmark_failures.csv" ]; then
    echo "ğŸ—‘ï¸  Removing previous benchmark_failures.csv"
    rm benchmark_failures.csv
fi

echo ""
echo "ğŸ“‹ Running comprehensive benchmark suite..."
echo "   â€¢ Systems: ALL (CQ, Baloo, LogupGKR, Plookup, Caulk, Lasso)"
echo "   â€¢ K values: 5-12 (table sizes from 32 to 4096)"
echo "   â€¢ N:n ratios: 2, 4, 8, 16"
echo "   â€¢ Total tasks: ~192 (6 systems Ã— 8 k-values Ã— 4 ratios)"
echo "   â€¢ Output format: Table"
echo ""
echo "âš ï¸  Warning: This is a comprehensive benchmark that may take several hours!"
echo "    Results will be saved incrementally, so you can monitor progress."
echo ""

# Ask for confirmation
read -p "Do you want to proceed with this comprehensive benchmark? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "âŒ Benchmark cancelled."
    exit 1
fi

echo "ğŸš€ Starting comprehensive benchmark..."
echo "ğŸ’¾ Results will be saved to benchmark_results.csv as each test completes"
echo ""

# Run the benchmark
cd benchmark

echo "ğŸš€ Note: Running systems in two phases to avoid Lasso parallel race conditions"
echo "ğŸ“Š Phase 1: Lasso (sequential execution) - Thread-safe for multiple instances"
echo "ğŸ“Š Phase 2: Other systems (parallel execution) - No race condition issues"
echo "ğŸ’¾ Both phases will append results to the same CSV files automatically"
echo ""

# Phase 1: Run Lasso separately without parallel execution to avoid race conditions
echo "ğŸ“Š Phase 1: Running Lasso benchmarks (sequential execution)..."
echo "   ğŸ”§ Using --no-default-features to disable parallel execution and verbose timing logs"
echo "   ğŸ“ Results will be written to benchmark_results.csv"
echo ""
time cargo bench --bench proof_system --no-default-features -- \
    --system lasso \
    --k 5..14 \
    --ratio 2,4,8,16 \
    --format table

echo ""
echo "âœ… Phase 1 completed - Lasso results saved to CSV"
echo ""

# Phase 2: Run other systems with parallel execution (they don't have the race condition issue)
echo "ğŸ“Š Phase 2: Running other systems (parallel execution)..."
echo "   ğŸ”§ Using default parallel execution for optimal performance"
echo "   ğŸ“ Results will be appended to the same benchmark_results.csv"
echo ""
time cargo bench --bench proof_system -- \
    --system cq,baloo,logupgkr,plookup,caulk \
    --k 5..14 \
    --ratio 2,4,8,16 \
    --format table

echo ""
echo "âœ… Phase 2 completed - All system results saved to CSV"

echo ""
echo "ğŸ“Š Benchmark completed! Checking results..."

# Check if files exist and show their content
if [ -f "benchmark_results.csv" ]; then
    echo ""
    echo "âœ… benchmark_results.csv created successfully!"
    echo "ğŸ“ File size: $(wc -c < benchmark_results.csv) bytes"
    echo "ğŸ“Š Number of results: $(($(wc -l < benchmark_results.csv) - 1))"
    echo ""
    echo "ğŸ“– First few lines:"
    head -5 benchmark_results.csv
    echo ""
    echo "ğŸ“– Last few lines:"
    tail -3 benchmark_results.csv
    echo ""
    echo "ğŸ“ˆ Results by system:"
    tail -n +2 benchmark_results.csv | cut -d',' -f1 | sort | uniq -c | sort -nr
else
    echo "âŒ benchmark_results.csv not found!"
fi

if [ -f "benchmark_failures.csv" ]; then
    if [ -s "benchmark_failures.csv" ]; then
        echo ""
        echo "âš ï¸  benchmark_failures.csv contains failures:"
        echo "ğŸ“ File size: $(wc -c < benchmark_failures.csv) bytes"
        echo "âŒ Number of failures: $(($(wc -l < benchmark_failures.csv) - 1))"
        echo ""
        echo "ğŸ“– Failure summary by system:"
        tail -n +2 benchmark_failures.csv | cut -d',' -f1 | sort | uniq -c | sort -nr
        echo ""
        echo "ğŸ“– First few failure details:"
        head -5 benchmark_failures.csv
    else
        echo ""
        echo "âœ… benchmark_failures.csv exists but is empty (no failures)"
    fi
else
    echo "âŒ benchmark_failures.csv not found!"
fi

echo ""
echo "ğŸ¯ Comprehensive Benchmark Features Demonstrated:"
echo "   âœ… All proof systems tested - CQ, Baloo, LogupGKR, Plookup, Caulk, Lasso"
echo "   âœ… Wide parameter range - k=5..12, ratios=2,4,8,16"
echo "   âœ… Incremental CSV writing - results saved as each benchmark completes"
echo "   âœ… Failure tracking - any failed benchmarks are logged separately"
echo "   âœ… Parallel execution - multiple benchmarks run simultaneously"
echo "   âœ… Progress tracking - real-time progress updates with percentages"
echo "   âœ… Comprehensive reporting - separate files for successes and failures"
echo ""
echo "ğŸ’¡ Benefits:"
echo "   ğŸ“ Partial results preserved even if the process is interrupted"
echo "   ğŸ” Easy identification of which specific configurations failed"
echo "   âš¡ Faster execution through parallelization"
echo "   ğŸ“Š Machine-readable CSV format for further analysis"
echo "   ğŸ¯ Complete coverage of all proof systems and parameters"
echo "   ğŸ“ˆ Automatic plot generation for all key performance metrics"
echo ""
echo "ğŸ—‚ï¸  Output files:"
echo "   ğŸ“Š benchmark_results.csv - All successful benchmark results"
echo "   âŒ benchmark_failures.csv - Any failed benchmark attempts"
echo "   ğŸ¨ plots/*.png - Automatically generated performance visualization plots"
echo ""

# Generate a quick analysis if we have results
if [ -f "benchmark_results.csv" ] && [ -s "benchmark_results.csv" ]; then
    echo "ğŸ“Š Quick Analysis:"
    echo "   â€¢ Total successful benchmarks: $(($(wc -l < benchmark_results.csv) - 1))"
    
    # Find fastest and slowest setups
    if [ $(wc -l < benchmark_results.csv) -gt 1 ]; then
        echo "   â€¢ Fastest setup time: $(tail -n +2 benchmark_results.csv | cut -d',' -f4 | sort -n | head -1)ms"
        echo "   â€¢ Slowest setup time: $(tail -n +2 benchmark_results.csv | cut -d',' -f4 | sort -n | tail -1)ms"
        echo "   â€¢ Fastest prove time: $(tail -n +2 benchmark_results.csv | cut -d',' -f5 | sort -n | head -1)ms"
        echo "   â€¢ Slowest prove time: $(tail -n +2 benchmark_results.csv | cut -d',' -f5 | sort -n | tail -1)ms"
    fi
fi

echo ""
echo "Done! ğŸ‰"
# Generate plots automatically if benchmarks completed successfully
if [ -f "benchmark_results.csv" ] && [ -s "benchmark_results.csv" ] && [ $(wc -l < "benchmark_results.csv") -gt 1 ]; then
    echo "ğŸ“Š Generating performance plots..."
    echo ""
    
    # Check if Python is available
    if command -v python3 &> /dev/null; then
        PYTHON_CMD="python3"
    elif command -v python &> /dev/null; then
        PYTHON_CMD="python"
    else
        echo "âš ï¸  Python not found. Skipping plot generation."
        echo "   You can manually generate plots later using: python diagram.py"
        PYTHON_CMD=""
    fi
    
    if [ -n "$PYTHON_CMD" ]; then
        # Create plots directory
        mkdir -p plots
        
        echo "ğŸ¨ Generating comprehensive performance plots..."
        echo "   ğŸ“Š Setup Time plots..."
        $PYTHON_CMD diagram.py --metrics SetupTime_ms --output-dir plots/ --protocols Lasso,LogupGKR,CQ,Plookup,Baloo,Caulk
        
        echo "   ğŸ” Verify Time plots..."
        $PYTHON_CMD diagram.py --metrics VerifyTime_ms --output-dir plots/ --protocols Lasso,LogupGKR,CQ,Plookup,Baloo,Caulk
        
        echo "   â±ï¸  Total Time plots..."
        $PYTHON_CMD diagram.py --metrics TotalTime_ms --output-dir plots/ --protocols Lasso,LogupGKR,CQ,Plookup,Baloo,Caulk
        
        echo "   ğŸ“¦ Proof Size plots..."
        $PYTHON_CMD diagram.py --metrics ProofSize_bytes --output-dir plots/ --protocols Lasso,LogupGKR,CQ,Plookup,Baloo,Caulk
        
        echo "   ğŸš€ Proving Time plots (original)..."
        $PYTHON_CMD diagram.py --metrics ProveTime_ms --output-dir plots/ --protocols Lasso,LogupGKR,CQ,Plookup,Baloo,Caulk
        
        echo ""
        echo "ğŸ“ˆ Plot generation completed!"
        echo ""
        
        # Show generated plots summary
        if [ -d "plots" ]; then
            PLOT_COUNT=$(ls -1 plots/*.png 2>/dev/null | wc -l)
            if [ $PLOT_COUNT -gt 0 ]; then
                echo "ğŸ¯ Generated $PLOT_COUNT performance plots in plots/ directory:"
                echo ""
                echo "ğŸ“Š Setup Time plots:"
                ls -1 plots/setuptimems_*.png 2>/dev/null | sed 's/^/   â€¢ /'
                echo ""
                echo "ğŸ” Verify Time plots:"
                ls -1 plots/verifytimems_*.png 2>/dev/null | sed 's/^/   â€¢ /'
                echo ""
                echo "â±ï¸  Total Time plots:"
                ls -1 plots/totaltimems_*.png 2>/dev/null | sed 's/^/   â€¢ /'
                echo ""
                echo "ğŸ“¦ Proof Size plots:"
                ls -1 plots/proofsizebytes_*.png 2>/dev/null | sed 's/^/   â€¢ /'
                echo ""
                echo "ğŸš€ Proving Time plots:"
                ls -1 plots/provetimems_*.png 2>/dev/null | sed 's/^/   â€¢ /'
                echo ""
            else
                echo "âš ï¸  No plots were generated (check for errors above)"
            fi
        fi
        
        echo "ğŸ’¡ Plot Usage:"
        echo "   â€¢ SetupTime: Shows preprocessing/setup performance across systems"
        echo "   â€¢ VerifyTime: Shows verification performance (important for deployment)"
        echo "   â€¢ TotalTime: Shows end-to-end performance including all phases"
        echo "   â€¢ ProofSize: Shows proof size comparison (important for storage/bandwidth)"
        echo "   â€¢ ProveTime: Shows core proving time performance"
        echo ""
        echo "ğŸ¨ Custom Plot Generation:"
        echo "   â€¢ All metrics for single ratio: python diagram.py --metrics SetupTime_ms,VerifyTime_ms,TotalTime_ms,ProofSize_bytes --single-ratio 4"
        echo "   â€¢ Specific protocols only: python diagram.py --metrics TotalTime_ms --protocols Lasso,LogupGKR"
        echo "   â€¢ Different output directory: python diagram.py --output-dir custom_plots/"
        echo ""
    fi
else
    echo "âš ï¸  No benchmark results available for plot generation."
fi

echo ""
echo "ğŸ’¡ Next steps:"
echo "   â€¢ Review generated plots in plots/ directory for performance insights"
echo "   â€¢ Analyze benchmark_results.csv for detailed numerical data"
echo "   â€¢ Check benchmark_failures.csv for any issues that need attention"
echo "   â€¢ Use the CSV data and plots for research or optimization decisions" 